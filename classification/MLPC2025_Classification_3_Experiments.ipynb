{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ed14a9f-36ce-42ba-8914-fae1fb49abb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, balanced_accuracy_score, precision_score, average_precision_score,\n",
    "    recall_score, f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    ")\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "import IPython\n",
    "os.environ['NUMBA_CACHE_DIR'] = IPython.paths.get_ipython_cache_dir()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7625f0c7-0731-40c8-80ab-071f57612f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the user's home directory (e.g., 'C:\\Users\\user')\n",
    "DATA_DIR = r\"C:\\Users\\ferit\\MLPC2025_classification\"\n",
    "metadata_dir = os.path.join(DATA_DIR, 'metadata.csv')\n",
    "features_dir = os.path.join(DATA_DIR, 'audio_features')\n",
    "labels_dir = os.path.join(DATA_DIR, 'labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714cf054-05e9-46b5-b8f6-b185aaba1ea4",
   "metadata": {},
   "source": [
    "#### Load Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f25611e-3986-4659-b24a-9acabf63ad7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Metadata & Training Files\n",
    "metadata = pd.read_csv(metadata_dir)\n",
    "train_files = metadata.sample(len(metadata), random_state=42)[\"filename\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474d7220-f1de-4ec7-95e7-14724e32b6db",
   "metadata": {},
   "source": [
    "#### Load categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c49b997d-b89f-407a-a009-e37f473392e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names of Label Classes: \n",
      " ['Airplane', 'Alarm', 'Beep/Bleep', 'Bell', 'Bicycle', 'Bird Chirp', 'Bus', 'Car', 'Cat Meow', 'Chainsaw', 'Clapping', 'Cough', 'Cow Moo', 'Cowbell', 'Crying', 'Dog Bark', 'Doorbell', 'Drip', 'Drums', 'Fire', 'Footsteps', 'Guitar', 'Hammer', 'Helicopter', 'Hiccup', 'Horn Honk', 'Horse Neigh', 'Insect Buzz', 'Jackhammer', 'Laughter', 'Lawn Mower', 'Motorcycle', 'Piano', 'Pig Oink', 'Power Drill', 'Power Saw', 'Rain', 'Rooster Crow', 'Saxophone', 'Sewing Machine', 'Sheep/Goat Bleat', 'Ship/Boat', 'Shout', 'Singing', 'Siren', 'Sneeze', 'Snoring', 'Speech', 'Stream/River', 'Thunder', 'Train', 'Truck', 'Trumpet', 'Vacuum Cleaner', 'Violin', 'Washing Machine', 'Waves', 'Wind']\n"
     ]
    }
   ],
   "source": [
    "# Select a random audio file and its annotations\n",
    "np.random.seed(1)\n",
    "sample_file = np.random.choice(metadata['filename'].tolist())\n",
    "\n",
    "# Load corresponding label file\n",
    "label_filename = sample_file.replace('.mp3', '_labels.npz')\n",
    "label_path = os.path.join(DATA_DIR, 'labels', label_filename)\n",
    "labels = np.load(label_path)\n",
    "\n",
    "# Load categories\n",
    "categories = list(labels.keys())\n",
    "print(\"Names of Label Classes: \\n\", categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37058d3b-d26f-4174-8c95-5322747c3660",
   "metadata": {},
   "source": [
    "#### Aggregate Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "529896c9-60c7-40c9-862c-86117ba226c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate Labels\n",
    "def aggregate_labels(file_labels):\n",
    "    __y = []\n",
    "    for frame_labels in file_labels:\n",
    "        if(sum(frame_labels) == 0):\n",
    "            __y.append([0])\n",
    "        elif(np.count_nonzero(frame_labels) == len(frame_labels)):\n",
    "             __y.append([1])\n",
    "        else: #The annotators don't agree on the label\n",
    "            __y.append([np.random.choice(frame_labels)])\n",
    "    return __y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516c5567-a6ab-4590-8110-d4b147d44f12",
   "metadata": {},
   "source": [
    "### Split Train Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b858f5-4bcb-4d29-a35a-fa469fedece1",
   "metadata": {},
   "source": [
    "#### Read Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "531136e3-6703-49dc-b15c-adeed0e2ea9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read files and split train data\n",
    "import itertools\n",
    "def read_files(file_names, num_to_read=(len(train_files))):\n",
    "    X_train = []\n",
    "    Y_train = {}\n",
    "    for c in categories:\n",
    "        Y_train[c] = []\n",
    "    for f in file_names[:num_to_read]:\n",
    "        if not os.path.exists(os.path.join(features_dir , f.split('.')[0] + '.npz')):\n",
    "            continue\n",
    "        features = np.load(os.path.join(features_dir , f.split('.')[0] + '.npz'))[\"embeddings\"]\n",
    "        X_train.append(features)\n",
    "        y = np.load(os.path.join(labels_dir , f.split('.')[0] + '_labels.npz'))\n",
    "        for c in categories:\n",
    "            _y = aggregate_labels(y[c])\n",
    "            Y_train[c].extend(list(itertools.chain.from_iterable(_y)))\n",
    "    X_train = np.concatenate(X_train)\n",
    "    return X_train, Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2715dc-bee5-498e-8603-5c0168a7edb4",
   "metadata": {},
   "source": [
    "#### Split data without data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "178e3b8c-4f92-4e2f-9e6f-061c850d6479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train files      : 5761\n",
      "Number of validation files : 1646\n",
      "Number of test files       : 823\n"
     ]
    }
   ],
   "source": [
    "# Split data without data leakage\n",
    "train_files, test_files = train_test_split(metadata[\"filename\"].unique(), test_size=0.3, random_state=42)\n",
    "valid_files, test_files = train_test_split(test_files, test_size=1/3, random_state=42)\n",
    "#So final split: 70% train, 20% validation, 10% test\n",
    "\n",
    "# Print number of train, validation and test files\n",
    "print(\"Number of train files      :\",len(train_files))\n",
    "print(\"Number of validation files :\",len(valid_files))\n",
    "print(\"Number of test files       :\",len(test_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b41c3da-c70c-49c7-a730-4bd6cc8ad0d4",
   "metadata": {},
   "source": [
    "#### Load train & test (subset) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a1e4c55-5264-4449-a531-9a57fbab473f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# High computational effort!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9df882b5-1dac-4ddb-b4d8-1910aafa36c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shapes      (raw): (52214, 768) 58\n",
      "Validation shapes (raw): (14673, 768) 58\n",
      "Test shapes       (raw): (7431, 768) 58\n"
     ]
    }
   ],
   "source": [
    "# Load train & test data\n",
    "split = 40\n",
    "X_train_raw, Y_train = read_files(train_files, split * 7)\n",
    "X_valid_raw, Y_valid = read_files(valid_files, split * 2)\n",
    "X_test_raw, Y_test = read_files(test_files, split * 1)\n",
    "\n",
    "# print raw feature tensor shapes\n",
    "print(\"Train shapes      (raw):\", X_train_raw.shape, len(Y_train))\n",
    "print(\"Validation shapes (raw):\", X_valid_raw.shape, len(Y_valid))\n",
    "print(\"Test shapes       (raw):\", X_test_raw.shape, len(Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885299fc-0be7-4031-b30a-9eb5138b80b7",
   "metadata": {},
   "source": [
    "### Apply Feature Normalization & PCA dimensionality reduction (with 95% explained variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a2b82a-2b53-42be-9573-e05b1ef8ae33",
   "metadata": {},
   "source": [
    "#### Feature Tensor Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01b1e8d9-7890-451c-92da-853420c5f88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Compute scaling parameters ONLY on training data\n",
    "scaler = StandardScaler().fit(X_train_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf90f94-27fc-4bff-954f-147b1a5ccf43",
   "metadata": {},
   "source": [
    "#### Scale & Normalize Feature Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb9d4dd8-004c-4558-80f1-c9e75680d3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shapes      (scaled): (52214, 768) 58\n",
      "Validation shapes (scaled): (14673, 768) 58\n",
      "Test shapes       (scaled): (7431, 768) 58\n"
     ]
    }
   ],
   "source": [
    "# Scale Train and Test Feature Tensor\n",
    "X_train_scaled = scaler.transform(X_train_raw)\n",
    "X_valid_scaled = scaler.transform(X_valid_raw)\n",
    "X_test_scaled = scaler.transform(X_test_raw)\n",
    "\n",
    "# print scaled feature tensor shapes\n",
    "print(\"Train shapes      (scaled):\", X_train_scaled.shape, len(Y_train))\n",
    "print(\"Validation shapes (scaled):\", X_valid_scaled.shape, len(Y_test))\n",
    "print(\"Test shapes       (scaled):\", X_test_scaled.shape, len(Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf7e081-63c0-4fd5-aeda-5bf23de22c53",
   "metadata": {},
   "source": [
    "#### Dimensionality reduction for Feature Tensor with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e59224e7-9ab0-4848-b2f6-8d40360aa3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shapes      (reduced): (52214, 149) 58\n",
      "Validation shapes (reduced): (14673, 149) 58\n",
      "Test shapes       (reduced): (7431, 149) 58\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# PCA dimensionality reduction with keeping 95% of the variance\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train = pca.fit_transform(X_train_scaled) # fit and transform train feature tensor\n",
    "X_valid = pca.transform(X_valid_scaled)     # transform validation feature tensor\n",
    "X_test = pca.transform(X_test_scaled)       # transform test feature tensor\n",
    "\n",
    "# print reduced feature tensor shapes\n",
    "print(\"Train shapes      (reduced):\", X_train.shape, len(Y_train))\n",
    "print(\"Validation shapes (reduced):\", X_valid.shape, len(Y_valid))\n",
    "print(\"Test shapes       (reduced):\", X_test.shape, len(Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936ec216-b8c6-4b01-aef9-030de54dbd6f",
   "metadata": {},
   "source": [
    "### Training Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfa7ea7-7934-4fab-ae29-c5215b255d2c",
   "metadata": {},
   "source": [
    "#### Class labels for GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1feac5d1-b1fb-42a7-b011-0fb4f6fe553e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels:       52214\n",
      "Validation labels:  14673\n",
      "Test labels:        7431\n"
     ]
    }
   ],
   "source": [
    "selected_classes = {'Speech'}\n",
    "\n",
    "# Multi-class labels\n",
    "Y_train_multi = np.array([Y_train[cls] for cls in selected_classes]).T\n",
    "Y_valid_multi = np.array([Y_valid[cls] for cls in selected_classes]).T\n",
    "Y_test_multi = np.array([Y_test[cls] for cls in selected_classes]).T\n",
    "\n",
    "# print multi-class label class shapes\n",
    "print(\"Train labels:      \", len(Y_train_multi))\n",
    "print(\"Validation labels: \", len(Y_valid_multi))\n",
    "print(\"Test labels:       \", len(Y_test_multi))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4a424b-6ee6-41ab-b9eb-63b04a2365d1",
   "metadata": {},
   "source": [
    "#### Macro-Averaged Balanced Accuracy Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "631ddf0d-a94e-4e11-8b95-ed400232a789",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# Macro-Averaged Balanced Accuracy\n",
    "def balanced_accuracy(Y_valid, Y_pred):\n",
    "    # Ensure arrays are 2D (reshape if 1D)\n",
    "    if Y_valid.ndim == 1:\n",
    "        Y_valid = Y_valid.reshape(-1, 1)\n",
    "    if Y_pred.ndim == 1:\n",
    "        Y_pred = Y_pred.reshape(-1, 1)\n",
    "        \n",
    "    n_labels = Y_valid.shape[1]\n",
    "    balanced_accuracies = []\n",
    "    \n",
    "    for i in range(n_labels):\n",
    "        score = balanced_accuracy_score(Y_valid[:, i], Y_pred[:, i])\n",
    "        balanced_accuracies.append(score)\n",
    "    \n",
    "    # Macro-average across labels\n",
    "    balanced_accuracy_macro = np.mean(balanced_accuracies)\n",
    "    \n",
    "    print(f\"Macro-Averaged Balanced Accuracy: {balanced_accuracy_macro:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b5abee-d27b-42ba-ab42-9f8044ffc2ad",
   "metadata": {},
   "source": [
    "#### Grid-kNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0de1934a-650e-4240-aed7-fa1e2215a133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# High computational effort!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c517a13f-cd2c-46e7-8b69-7a273de80e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    }
   ],
   "source": [
    "# Grid-kNN Classifier\n",
    "kNN = KNeighborsClassifier(weights='distance')\n",
    "grid_kNN = MultiOutputClassifier(kNN)\n",
    "\n",
    "# Parameter grid\n",
    "param_grid = {\n",
    "    'estimator__n_neighbors': [3, 10, 50, 100],\n",
    "    'estimator__metric': ['euclidean', 'manhattan', 'cosine']\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=grid_kNN,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,                         # n-fold cross-validation\n",
    "    scoring='balanced_accuracy',\n",
    "    verbose=2,                    # Print progress\n",
    "    n_jobs=-1                     # Use all CPU cores\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "start_time = time.time()                  # Start timer\n",
    "grid_search.fit(X_train, Y_train_multi)\n",
    "end_time = time.time()                    # End timer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125f1c20-625d-4a08-a919-fe91e5cf346d",
   "metadata": {},
   "source": [
    "#### Grid-kNN Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31ae84d8-ee7c-47d1-840f-e2b3c8658ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed in: 0h 3m 32.88s\n",
      "\n",
      "Best parameters: {'estimator__metric': 'cosine', 'estimator__n_neighbors': 50}\n",
      "\n",
      "Performance Metrics – Grid-kNN Classifier\n",
      "============================================================\n",
      "Macro-Averaged Balanced Accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Print traing time\n",
    "total_seconds = end_time - start_time\n",
    "hours = int(total_seconds // 3600)\n",
    "remaining_seconds = total_seconds % 3600\n",
    "minutes = int(remaining_seconds // 60)\n",
    "seconds = remaining_seconds % 60\n",
    "\n",
    "print(f\"\\nTraining completed in: {hours}h {minutes}m {seconds:.2f}s\")\n",
    "\n",
    "# Best parameters\n",
    "print(\"\\nBest parameters:\", grid_search.best_params_)\n",
    "best_knn_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on validation set\n",
    "Y_valid_pred = grid_search.predict(X_valid)\n",
    "\n",
    "# Grid-kNN Performance Metrics \n",
    "print(\"\\nPerformance Metrics – Grid-kNN Classifier\")\n",
    "print(\"=\" * 60)\n",
    "grid_kNN_perf = balanced_accuracy(Y_valid_multi, Y_valid_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e12d4c8-487a-44e0-9293-96d0c1b119d0",
   "metadata": {},
   "source": [
    "#### Save best kNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c8b93f8-a2b4-4c29-be84-e6abc78be815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_knn_model.joblib']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "# Save best model\n",
    "dump(best_knn_model, 'best_knn_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c82077e-446a-453f-aa11-cc6b554cd1bb",
   "metadata": {},
   "source": [
    "#### Grid-Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fd8a7ce-a788-4281-85fe-57c92fde4669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "grid_rf = MultiOutputClassifier(rf)\n",
    "\n",
    "# Parameter grid\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [100, 200, 300],\n",
    "    'estimator__max_depth': [5, 10, 20],\n",
    "    'estimator__min_samples_split': [2, 5],\n",
    "    'estimator__min_samples_leaf': [1, 2],\n",
    "    'estimator__max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=grid_rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,                         # n-fold cross-validation\n",
    "    scoring='balanced_accuracy',\n",
    "    verbose=3,\n",
    "    n_jobs=-1                     # Use all CPU cores\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "start_time = time.time()                  # Start timer\n",
    "grid_search.fit(X_train, Y_train_multi)\n",
    "end_time = time.time()                    # End timer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c2c3ca-4a3d-4c3d-a3d8-618956bb9d67",
   "metadata": {},
   "source": [
    "#### Grid-Random Forest Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d7bc4b3-6c85-4b6a-9a21-5d32941701bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed in: 0h 27m 34.95s\n",
      "\n",
      "Best parameters: {'estimator__max_depth': 20, 'estimator__max_features': 'sqrt', 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'estimator__n_estimators': 100}\n",
      "\n",
      "Performance Metrics – Grid-Random Forest Classifier\n",
      "============================================================\n",
      "Macro-Averaged Balanced Accuracy: 0.76\n"
     ]
    }
   ],
   "source": [
    "# Print traing time\n",
    "total_seconds = end_time - start_time\n",
    "hours = int(total_seconds // 3600)\n",
    "remaining_seconds = total_seconds % 3600\n",
    "minutes = int(remaining_seconds // 60)\n",
    "seconds = remaining_seconds % 60\n",
    "\n",
    "print(f\"\\nTraining completed in: {hours}h {minutes}m {seconds:.2f}s\")\n",
    "\n",
    "# Best parameters\n",
    "print(\"\\nBest parameters:\", grid_search.best_params_)\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on validation set\n",
    "Y_valid_pred = grid_search.predict(X_valid)\n",
    "\n",
    "# Grid-RF Performance Metrics \n",
    "print(\"\\nPerformance Metrics – Grid-Random Forest Classifier\")\n",
    "print(\"=\" * 60)\n",
    "grid_rf_perf = balanced_accuracy(Y_valid_multi, Y_valid_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba849c0-b608-410e-8e59-a4674799dedb",
   "metadata": {},
   "source": [
    "#### Save best Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d8e7800-c956-4ce3-98fe-5530b76e50ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_rf_model.joblib']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "# Save best model\n",
    "dump(best_rf_model, 'best_rf_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f90a7b-8e89-4d17-9303-8fcdeb19edbd",
   "metadata": {},
   "source": [
    "#### Grid-XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "929c636e-1010-471d-a15b-93c34600c9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 512 candidates, totalling 1536 fits\n"
     ]
    }
   ],
   "source": [
    "# Grid-XGBoost Classifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# XGBoost Model Configuration\n",
    "grid_xgb = XGBClassifier(random_state=42)\n",
    "\n",
    "# Parameter grid\n",
    "param_grid = {\n",
    "    'estimator__learning_rate': [0.05, 0.1],\n",
    "    'estimator__n_estimators': [300, 400],\n",
    "    'estimator__max_depth': [6, 8],\n",
    "    'estimator__max_bin': [256, 512],\n",
    "    'estimator__gamma': [0, 0.1],\n",
    "    'estimator__reg_alpha': [0, 0.1],\n",
    "    'estimator__reg_lambda': [0.5, 1],\n",
    "    'estimator__subsample': [0.8, 1.0],\n",
    "    'estimator__colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=grid_xgb,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring='balanced_accuracy',\n",
    "    verbose=1,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "start_time = time.time()                  # Start timer\n",
    "grid_search.fit(X_train, Y_train_multi)\n",
    "end_time = time.time()                    # End timer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8babaae0-d3fa-4787-97f7-e80ba024ff10",
   "metadata": {},
   "source": [
    "#### Grid-XGBoost Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "079c3060-6439-4a9a-9705-d17564714869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed in: 0h 21m 10.23s\n",
      "\n",
      "Best parameters: {'estimator__colsample_bytree': 0.8, 'estimator__gamma': 0, 'estimator__learning_rate': 0.05, 'estimator__max_bin': 256, 'estimator__max_depth': 6, 'estimator__n_estimators': 300, 'estimator__reg_alpha': 0, 'estimator__reg_lambda': 0.5, 'estimator__subsample': 0.8}\n",
      "\n",
      "Performance Metrics – Grid-XGBoost Classifier\n",
      "============================================================\n",
      "Macro-Averaged Balanced Accuracy: 0.78\n"
     ]
    }
   ],
   "source": [
    "# Print traing time\n",
    "total_seconds = end_time - start_time\n",
    "hours = int(total_seconds // 3600)\n",
    "remaining_seconds = total_seconds % 3600\n",
    "minutes = int(remaining_seconds // 60)\n",
    "seconds = remaining_seconds % 60\n",
    "\n",
    "print(f\"\\nTraining completed in: {hours}h {minutes}m {seconds:.2f}s\")\n",
    "\n",
    "# Best parameters\n",
    "print(\"\\nBest parameters:\", grid_search.best_params_)\n",
    "best_xgb_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on validation set\n",
    "Y_valid_pred = grid_search.predict(X_valid)\n",
    "\n",
    "# Grid-XGBoost Performance Metrics \n",
    "print(\"\\nPerformance Metrics – Grid-XGBoost Classifier\")\n",
    "print(\"=\" * 60)\n",
    "grid_xgb_perf = balanced_accuracy(Y_valid_multi, Y_valid_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2041b402-aa82-424a-9b30-9be8f974a75a",
   "metadata": {},
   "source": [
    "#### Save best XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67f797d2-11f9-4f71-86ea-7985c45df154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_xgb_model.joblib']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "# Save best model\n",
    "dump(best_xgb_model, 'best_xgb_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f64f3e-159b-44d6-9726-018b59204902",
   "metadata": {},
   "source": [
    "#### Grid-Neural Network Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7550c195-0dc9-4090-b959-72f4678b577d",
   "metadata": {},
   "source": [
    "#### CUDA availability check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38f72bc3-5f65-4076-992a-46b4e45f69d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA version: 12.8\n",
      "Using GPU: NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA version:\",torch.version.cuda)\n",
    "\n",
    "# CUDA availability check\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e4c2e0-e0f7-4cf3-a9bc-539c6e8774c4",
   "metadata": {},
   "source": [
    "#### Convert data to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62f63f60-4aa6-4198-b833-3c30d90fa709",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "Y_train_tensor = torch.FloatTensor(Y_train_multi)\n",
    "X_test_tensor = torch.FloatTensor(X_valid)\n",
    "Y_test_tensor = torch.FloatTensor(Y_valid_multi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fd1290-6eb4-4ecf-8d28-9cf419f83a9f",
   "metadata": {},
   "source": [
    "#### Neural Network Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d30dbf81-50a2-49c3-89a4-ce839b0f1744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Classifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Simple neural network model\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1=128, hidden_size2=64, output_size=1):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.layer2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.output = nn.Linear(hidden_size2, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acfa2e17-ac2f-44fd-99d6-190496ed5e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    }
   ],
   "source": [
    "from skorch import NeuralNetClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import torch.optim as optim\n",
    "\n",
    "# Wrap the SimpleNN in a skorch classifier\n",
    "net = NeuralNetClassifier(\n",
    "    module=SimpleNN,\n",
    "    module__input_size=X_train_tensor.shape[1],\n",
    "    criterion=nn.BCELoss,\n",
    "    optimizer=optim.Adam,\n",
    "    max_epochs=10,\n",
    "    batch_size=256,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Parameter grid\n",
    "param_grid = {\n",
    "    'lr': [0.001, 0.01],\n",
    "    'module__hidden_size1': [64, 128],\n",
    "    'module__hidden_size2': [32, 64],\n",
    "    'optimizer__weight_decay': [0, 0.001]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_nn = GridSearchCV(\n",
    "    estimator=net,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring='balanced_accuracy',\n",
    "    verbose=1,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "start_time = time.time()\n",
    "grid_search_nn.fit(X_train_tensor, Y_train_tensor)\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234eff21-f79a-4697-9cd1-7b8456778e96",
   "metadata": {},
   "source": [
    "#### Grid-SimlpleNN Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9d319bb-ce2e-49a8-9ba7-355a745ea080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed in: 0h 3m 46.87s\n",
      "\n",
      "Best parameters: {'lr': 0.01, 'module__hidden_size1': 64, 'module__hidden_size2': 32, 'optimizer__weight_decay': 0.001}\n",
      "\n",
      "Performance Metrics - Neural Network Classifier\n",
      "============================================================\n",
      "Macro-Averaged Balanced Accuracy: 0.81\n"
     ]
    }
   ],
   "source": [
    "# Print training time\n",
    "total_seconds = end_time - start_time\n",
    "hours = int(total_seconds // 3600)\n",
    "remaining_seconds = total_seconds % 3600\n",
    "minutes = int(remaining_seconds // 60)\n",
    "seconds = remaining_seconds % 60\n",
    "print(f\"\\nTraining completed in: {hours}h {minutes}m {seconds:.2f}s\")\n",
    "\n",
    "# Best parameters\n",
    "print(\"\\nBest parameters:\", grid_search_nn.best_params_)\n",
    "best_nn_model = grid_search_nn.best_estimator_\n",
    "\n",
    "# Predict on validation set\n",
    "Y_valid_pred = best_nn_model.predict(X_test_tensor)\n",
    "\n",
    "# Neural Network Performance Metrics \n",
    "print(\"\\nPerformance Metrics - Neural Network Classifier\")\n",
    "print(\"=\" * 60)\n",
    "balanced_accuracy(Y_valid_multi, Y_valid_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f36e73-25d1-4d1c-9086-be3fc7b9e9fc",
   "metadata": {},
   "source": [
    "#### Save best SimpleNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24d11bae-1ee9-400b-83f3-e225abcd9395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Save the entire model (architecture + weights + optimizer state)\n",
    "torch.save(best_nn_model.module_, 'best_nn_model.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
